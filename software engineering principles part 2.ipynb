{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3cf0057",
   "metadata": {},
   "source": [
    "## **Some Advanced Software Engineering Principles for Clean & Reusable Python Code: Part 2**   \n",
    "\n",
    "You've done everything possible to make your code reproducible and reusable. You've followed best practices, named your variables like a responsible adult, and even added comments that you *might* understand six months from now. But now you’ve realised that some of these tasks are getting a bit too repetitive, like déjà vu with less excitement.\n",
    "\n",
    "Writing the same block of code over and over every time you encounter a familiar objective? Yes, that’s not exactly the dream. To make life easier (and to protect your sanity), it's time to streamline the process. And guess what? You couldn’t find any existing helper libraries or packages tailored specifically for your needs. So what do you do? You build your own `Python` package, of course – from scratch, fully customisable, and exactly how *you* like it.\n",
    "\n",
    "You can keep it for yourself, use it locally like a secret weapon, or share it with the world by indexing it on [PyPI](https://pypi.org/) (the Python Package Index) and bask in the glory of open-source contribution.\n",
    "\n",
    "In this article, we won’t just dump code and call it a day. Instead, we’ll walk through the basic structure of a Python package designed for analytics tasks. We'll build it from scratch, test it, format it, and finally publish it to `PyPI`. Our package will be simple but functional, and will focus on:\n",
    "\n",
    "#### An Extract, Transform, and Load (ETL) Pipeline for CSV Data\n",
    "\n",
    "1. The package will list and transform any number of CSV files from a local directory.\n",
    "2. It will load the integrated and transformed dataset into a PostgreSQL database ([PostgreSQL](https://www.postgresql.org/)).\n",
    "\n",
    "Let’s dive in and have some fun building your own package. Who knows, this might be the start of your open-source empire.\n",
    "\n",
    "\n",
    "![](https://plus.unsplash.com/premium_photo-1720287601300-cf423c3d6760?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D)\n",
    "\n",
    "Photo by [Philip Oroni](https://unsplash.com/@philipsfuture) on [Unsplash](https://unsplash.com/)\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Developing a Python Package**  \n",
    "A package is a **collection of modules**.\n",
    "\n",
    "Difference between a `script`, `module`, and `package`:\n",
    "\n",
    "- A **script** is generally a standalone Python file (`.py`) intended to be executed directly. It might contain plain lines of code, functions, or objects. Scripts often include the following line of code to specify that certain code should only run when the file is executed directly, not when imported as a module:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running some code!\") # The function(s)/code intended to be run goes in this block\n",
    "```\n",
    "\n",
    "- A **module** is a Python file (`.py`) containing functions, classes, and variables that can be imported and used in other scripts or modules.\n",
    "\n",
    "- A **package** is a collection of one or more modules, sub-packages (packages within packages), and scripts. It is typically organised as a directory containing Python files and optionally an `__init__.py` file to mark it as a package.\n",
    "\n",
    "Below is an example structure of the package we're going to build, showing only the key modules, subpackage, and scripts (with a brief description of each in comments using `#`).\n",
    "\n",
    "### **Example: An ETL (Extract, Transform, and Load) Package**\n",
    "\n",
    "```python\n",
    "my_etl_package (top-level/parent directory of the package)\n",
    "├── my_etl_package (main package)  \n",
    "│   ├── __init__.py            # Organises imports of modules and their functions for the main package  \n",
    "│   ├── load_data.py           # Handles loading data into the database  \n",
    "│   ├── read_data.py           # Reads raw CSV files from local storage  \n",
    "│   ├── transform_data.py      # Applies transformations to raw data  \n",
    "│   ├── write_data.py          # Writes cleaned data to intermediate storage or output  \n",
    "│   ├── utils (subpackage) \n",
    "│   │   ├── __init__.py        # Organises imports of modules and their functions within the subpackage  \n",
    "│   │   ├── connect_db.py      # Manages database connections  \n",
    "│   │   └── fetch_files.py     # Fetches file paths and performs file-level checks  \n",
    "├── setup.py                   # Package configuration and metadata  \n",
    "├── main.py                    # Example script demonstrating usage of the package and subpackage  \n",
    "└── ... [other files for testing, formatting, documentation, etc.]\n",
    "```\n",
    "\n",
    "__Note:__ Actually a common convention in Python projects to have both the top-level project folder and the importable package (main package) folder share the same name.\n",
    "\n",
    "While it is beyond the scope of this article to discuss each module in detail, the source code for all of them is provided at the end. The code is well-documented, type-annotated, formatted, and tested for production-level use. In this section, we will only briefly discuss how to structure imports within the __init__.py files, as well as at the top-level directory (i.e. outside the package itself), which reflects how the package would be utilised if installed in an external environment or from a different directory (more on this later).\n",
    "\n",
    "---\n",
    "\n",
    "#### 1.1. Structuring Imports\n",
    "\n",
    "#### a) Importing Modules and Functions from Packages and Sub-packages in Python\n",
    "\n",
    "When working with a structured Python project, you often want to import modules or specific functions from a package or sub-package into a top-level script like `main.py`. This can be done in multiple ways, depending on your preference for clarity, scope, and modularity.\n",
    "\n",
    "#### **Method 1: Direct Module Import**\n",
    "\n",
    "You can import entire modules from a package or sub-package and then access their functions or classes using dot notation.\n",
    "\n",
    "**Example Import Structure:**\n",
    "\n",
    "```\n",
    "my_etl_package/\n",
    "│\n",
    "├── main.py\n",
    "└── my_etl_package/\n",
    "    ├── __init__.py\n",
    "    ├── load_data.py\n",
    "    ├── read_data.py\n",
    "    ├── transform_data.py\n",
    "    ├── write_data.py   \n",
    "    └── utils/\n",
    "        ├── __init__.py\n",
    "        ├── connect_db.py \n",
    "        └── fetch_files.py\n",
    "```\n",
    "\n",
    "**Usage in `main.py`:**\n",
    "\n",
    "```python\n",
    "# Importing the module from the package\n",
    "from my_etl_package import read_data  \n",
    "read_data.read_csv(...)\n",
    "\n",
    "or\n",
    "import my_etl_package.read_data\n",
    "my_etl_package.read_data.read_csv(...)\n",
    "\n",
    "# Importing the module from the sub-package\n",
    "from my_etl_package.utils import fetch_files  \n",
    "fetch_files.list_csv_files(...)\n",
    "\n",
    "or\n",
    "import my_etl_package.utils.fetch_files \n",
    "my_etl_package.utils.fetch_files.list_csv(...)\n",
    "```\n",
    "\n",
    "This approach makes it easy to trace where a function or class came from.\n",
    "\n",
    "#### **Method 2: Direct Function Import via `__init__.py`**\n",
    "\n",
    "You can expose specific functions or classes at the package level by importing them in the `__init__.py` file of the package or sub-package. This allows direct access to those functions without having to go through the module path.\n",
    "\n",
    "**Inside `my_etl_package/__init__.py`:**\n",
    "\n",
    "```python\n",
    "from my_etl_package.read_data import read_csv\n",
    "```\n",
    "\n",
    "**Inside `my_etl_package/utils/__init__.py`:**\n",
    "\n",
    "```python\n",
    "from my_etl_package.utils.fetch_files import list_csv_files\n",
    "```\n",
    "\n",
    "**Usage in `main.py`:**\n",
    "\n",
    "```python\n",
    "# Direct function access after exposing via __init__.py\n",
    "from my_etl_package import read_csv  \n",
    "read_csv(...)\n",
    "\n",
    "from my_etl_package.utils import list_csv_files  \n",
    "list_csv_files(...)\n",
    "```\n",
    "\n",
    "This method helps encapsulate complexity within the package.\n",
    "\n",
    "Direct function imports via `__init__.py` are better for keeping imports short and clean, especially in top-level scripts. They make the code easier to read and maintain by avoiding long module paths.\n",
    "\n",
    "This kind of imports are called `absolute` imports, which are preferred. You can also use `relative` imports where you don't specifically mention the name but use `.` (dot) notation, where one `.` means the current directory, and two `..` mean the parent of the current directory. For example:\n",
    "\n",
    "**Inside `my_etl_package/__init__.py`:**\n",
    "\n",
    "```python\n",
    "from .read_data import read_csv\n",
    "```\n",
    "\n",
    "**Inside `my_etl_package/utils/__init__.py`:**\n",
    "\n",
    "```python\n",
    "from .fetch_files import list_csv_files\n",
    "```\n",
    "\n",
    "This is shorter; however, it might cause conflicts later if not installed as a package, therefore not recommended.\n",
    "\n",
    "#### Method 3: Chained Exposure via **init**.py\n",
    "\n",
    "To allow top-level access to deeply nested modules or functions, you can chain imports through `__init__.py` files of each package or sub-package. To do that, we first need to import the modules, functions, and sub-packages into the __init__.py file of the package, and then import the modules and functions of the sub-package into the __init__.py file of the sub-package.\n",
    "\n",
    "**Inside `my_etl_package/__init__.py`:**\n",
    "\n",
    "```python\n",
    "from my_etl_package import utils\n",
    "from my_etl_package import read_data\n",
    "from my_etl_package.read_data import read_csv\n",
    "```\n",
    "\n",
    "**Inside `my_etl_package/utils/__init__.py`:**\n",
    "\n",
    "```python\n",
    "from my_etl_package.utils import fetch_files\n",
    "from my_etl_package.utils.fetch_files import list_csv_files\n",
    "```\n",
    "\n",
    "**Usage in `main.py`:**\n",
    "\n",
    "```python\n",
    "import my_etl_package\n",
    "\n",
    "my_etl_package.read_data.read_csv(...)\n",
    "or\n",
    "my_etl_package.read_csv(...)\n",
    "\n",
    "my_etl_package.utils.fetch_files.list_csv_files(...)\n",
    "or\n",
    "my_etl_package.utils.list_csv_files(...)\n",
    "```\n",
    "\n",
    "#### b) Importing Between Modules (Sibling Imports) or Modules in Different Levels\n",
    "\n",
    "Similarly, both `absolute` and `relative` imports can be used. For example:\n",
    "\n",
    "**Inside `my_etl_package/transform_data.py`:**\n",
    "\n",
    "```python\n",
    "from .read_data import read_csv\n",
    "or \n",
    "from my_etl_package.read_data import read_csv\n",
    "```\n",
    "\n",
    "**Inside `my_etl_package/utils/*` from a module (`test.py`) on one level up (`my_etl_package/*`):**\n",
    "\n",
    "```python\n",
    "from ..test import test_func\n",
    "```\n",
    "\n",
    "####  Important Note: Avoid Circular Imports When Importing Between Modules\n",
    "\n",
    "When importing functions between modules within the same package, **do not import them from the package level** (i.e., avoid accessing them via the `__init__.py`-exposed shortcut). For example;\n",
    "\n",
    "In `my_etl_package/__init__.py`:\n",
    "\n",
    "```python\n",
    "from my_etl_package.read_data import read_csv\n",
    "```\n",
    "\n",
    "**Incorrect – will likely cause a circular import error:**\n",
    "\n",
    "In `transform_data.py`:\n",
    "\n",
    "```python\n",
    "from my_etl_package import read_csv  # Causes circular import\n",
    "```\n",
    "\n",
    "This causes a circular import because:\n",
    "\n",
    "* `transform_data.py` depends on a function (`read_csv`) exposed at the **package level** via `__init__.py`.\n",
    "* But the package level (`__init__.py`) may itself depend on `transform_data.py` or other modules — creating an import loop.\n",
    "\n",
    "**Correct – use direct modular imports between modules:**\n",
    "\n",
    "In `transform_data.py`:\n",
    "\n",
    "```python\n",
    "from my_etl_package.read_data import read_csv  # Safe and clear\n",
    "```\n",
    "\n",
    "This avoids unnecessary coupling and prevents circular dependencies.\n",
    "\n",
    "__Note:__ `main.py` is not part of the package (added optionally here). It serves as a testing ground/implementation for various parts of the package from the package’s parent or top-level directory.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1.2. Setting up the Package\n",
    "\n",
    "You've developed all the modules and sub-packages in your package, but right now it's only available in the package's top-level directory. This means it's inaccessible outside that directory even within the same environment on your local machine. To be able to import and use it in any other directory or script within the same environment, you must first install it locally within that environment.\n",
    "\n",
    "Once installed, the import structure will remain the same regardless of the script's location, as long as you're running the code within the same environment. If you want to use the package in a different environment, you'll need to install it there separately.\n",
    "\n",
    "To install the package locally in your working environment, you need a `setup.py` file. This file tells Python what to install and includes metadata about your package. Below is a sample `setup.py` file:\n",
    "\n",
    "```python\n",
    "from setuptools import setup, find_packages\n",
    "import io\n",
    "import os\n",
    "\n",
    "\n",
    "# Read README.md for the long description\n",
    "with io.open(\n",
    "    os.path.join(os.path.dirname(__file__), \"README.md\"), encoding=\"utf-8\"\n",
    ") as f:\n",
    "    long_description = f.read()\n",
    "\n",
    "setup(\n",
    "    name=\"my_etl_package\",\n",
    "    version=\"1.0.0\",\n",
    "    description=\"A package for ETL pipeline operations\",\n",
    "    long_description=long_description,\n",
    "    long_description_content_type=\"text/markdown\",\n",
    "    author=\"Khaled Ahmed\",\n",
    "    author_email=\"khhaledahmaad@gmail.com\",\n",
    "    packages=find_packages(include=[\"my_etl_package\", \"my_etl_package.*\"]),\n",
    "    python_requires=\">=3.10\",\n",
    "    install_requires=[\n",
    "        \"python-dotenv\",\n",
    "        \"numpy\",\n",
    "        \"pandas\",\n",
    "        \"sqlalchemy\",\n",
    "    ],\n",
    "    classifiers=[\n",
    "        \"Development Status :: 4 - Beta\",\n",
    "        \"Environment :: Other Environment\",\n",
    "        \"Intended Audience :: Developers\",\n",
    "        \"License :: OSI Approved :: MIT License\",\n",
    "        \"Operating System :: OS Independent\",\n",
    "        \"Programming Language :: Python\",\n",
    "        \"Programming Language :: Python :: 3.10\",\n",
    "        \"Programming Language :: Python :: 3.11\",\n",
    "        \"Topic :: Software Development\",\n",
    "        \"Topic :: Software Development :: Libraries :: Python Modules\",\n",
    "    ],\n",
    ")\n",
    "```\n",
    "\n",
    "You can then install the package in **editable mode**, which allows you to modify the package source code without needing to reinstall it each time:\n",
    "\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "Once you've finalised your package, you can list and save all the dependencies by running the following command from the top-level directory:\n",
    "\n",
    "```bash\n",
    "pip freeze > requirements.txt\n",
    "```\n",
    "\n",
    "This is different from the `install_requires` parameter in the `setup.py` file:\n",
    "\n",
    "* **`install_requires`** is intended for **users** of the package. It specifies the core dependencies with version flexibility to ensure compatibility.\n",
    "* **`requirements.txt`** is typically for **developers**. It lists **exact versions** of all dependencies in the current environment, ensuring consistent builds and reproducibility.\n",
    "\n",
    "#### **What are classifiers?**\n",
    "\n",
    "Classifiers (also called **Trove classifiers**) are **standardised metadata tags** for Python packages. They are a set of predefined strings that describe:\n",
    "\n",
    "* The **maturity** of the project\n",
    "* Its **audience**\n",
    "* The **programming language versions** it supports\n",
    "* The **environment** it runs in\n",
    "* Its **topic or purpose**\n",
    "\n",
    "You can see the full list here: [PyPI Classifiers](https://pypi.org/classifiers/)\n",
    "\n",
    "#### **Purpose of classifiers**\n",
    "\n",
    "1. **Help users discover your package**\n",
    "\n",
    "   * On PyPI (where developers usually publish their package to make it usable for other users—more on this later), users can filter or search packages by these tags.\n",
    "   * Example: If someone searches for “Python 3.11 libraries for data processing,” valid classifiers make your package show up in the results.\n",
    "\n",
    "2. **Give clear metadata about your package**\n",
    "\n",
    "   * Developers and tools can immediately understand:\n",
    "\n",
    "     * Supported Python versions (`Programming Language :: Python :: 3.10`)\n",
    "     * License (`License :: OSI Approved :: MIT License`)\n",
    "     * Intended audience (`Intended Audience :: Developers`)\n",
    "\n",
    "3. **Prevent metadata errors during upload**\n",
    "\n",
    "   * PyPI validates these classifiers when you upload a package.\n",
    "   * **Invalid classifiers** (like `\"Topic :: ETL\"`) cause **HTTP 400 Bad Request errors**.\n",
    "\n",
    "\n",
    "#### **Example of what classifiers tell people**\n",
    "\n",
    "```python\n",
    "classifiers=[\n",
    "    \"Development Status :: 4 - Beta\",  # Package is in beta\n",
    "    \"Intended Audience :: Developers\", # For software developers\n",
    "    \"Programming Language :: Python :: 3.11\", # Supports Python 3.11\n",
    "    \"License :: OSI Approved :: MIT License\", # Open-source license\n",
    "    \"Topic :: Software Development :: Libraries :: Python Modules\", # It’s a library\n",
    "]\n",
    "```\n",
    "\n",
    "* This **instantly tells PyPI users** that your package is a beta Python library for developers, open-source, and works on Python 3.11.\n",
    "\n",
    "\n",
    "For more information on setting up a Setup Script ans all the options and metadata you can add: [Writing the Setup Script](https://docs.python.org/3.11/distutils/setupscript.html#)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Testing your Package\n",
    "You’ve spent days, maybe weeks, building your Python package. It’s clean, modular, and efficient. But how do you know it actually works? Not just on your machine—but in real-world use cases, across different components, under stress?\n",
    "\n",
    "This post is your practical guide to testing your Python package properly using tools like `pytest` and `unittest`. Whether you’re working on a personal project, a data pipeline, or preparing to publish your package to `PyPI`, the techniques here will help you ensure reliability and confidence in your code.\n",
    "\n",
    "#### 2.1. Why Test?\n",
    "\n",
    "Testing isn't just about finding bugs. It’s about validating assumptions, preventing regressions, and making collaboration sustainable. A well-tested package:\n",
    "\n",
    "* Catches issues early\n",
    "* Makes refactoring safer\n",
    "* Serves as documentation for intended behavior\n",
    "* Increases confidence in your work\n",
    "\n",
    "#### 2.2. Understanding Testing Methodologies\n",
    "\n",
    "Before we dive into writing code for testing, let's briefly understand the different types of testing.\n",
    "\n",
    "#### **Testing types in a broader context:**\n",
    "\n",
    "1. **Black Box Testing**\n",
    "   You test functionality *without* knowing the internal code. Think of using a well-documented external library; you're only concerned about input and output.\n",
    "\n",
    "2. **White Box Testing**\n",
    "   You test your *own* code with full knowledge of its logic and structure. You know what the functions are doing internally.\n",
    "\n",
    "3. **Gray Box Testing**\n",
    "   A hybrid approach. You have partial knowledge of the system. This is common in integration testing between third-party tools and your own logic.\n",
    "\n",
    "#### **Testing types at code level:**\n",
    "\n",
    "1. **Unit Testing**\n",
    "   Test individual units of functionality; typically functions or classes.\n",
    "\n",
    "2. **Feature Testing**\n",
    "   Tests that cover multiple units working together to achieve a specific feature or goal (e.g., a data import workflow).\n",
    "\n",
    "3. **Integration Testing**\n",
    "   Tests that check if different components (modules, packages, external services) are working together correctly.\n",
    "\n",
    "4. **Performance Testing**\n",
    "   Validates if the functions/modules perform efficiently under specific time constraints or large datasets.\n",
    "\n",
    "#### 2.3. Tools for Testing\n",
    "\n",
    "There are several tools you can use for testing in Python. Here's a quick comparison:\n",
    "\n",
    "`unittest`\n",
    "A built-in Python module that uses an object-oriented structure for writing test cases.\n",
    "\n",
    "`pytest`\n",
    "A third-party testing framework that is simpler, more expressive, and supports fixtures, plugins, and better error reporting out of the box.\n",
    "\n",
    "`tox`\n",
    "Used to automate testing across multiple Python environments. Ideal for package developers who want to maintain compatibility across versions.\n",
    "\n",
    "> Both pytest and unittest can be used interchangeably in many projects. You can mix both styles within the same test directory if needed, though most teams prefer to stick with one for consistency.\n",
    "\n",
    "| Tool           | Purpose                                         |\n",
    "| -------------- | ----------------------------------------------- |\n",
    "| **`unittest`** | Built-in testing module, class-based, OOP-style |\n",
    "| **`pytest`**   | Lightweight, more readable, feature-rich        |\n",
    "| **`tox`**      | Automates testing across Python versions        |\n",
    "\n",
    "In this article, we’ll focus primarily on `pytest`, but also show its close equivalents using `unittest` when relevant.\n",
    "\n",
    "#### 2.4. Structuring the Test Directory\n",
    "\n",
    "Organizing your test files clearly is key to maintainability. Ideally, your test directory should mirror the structure of your package. This makes it intuitive to locate and maintain tests, especially as the codebase grows. While there's no strict rule enforcing this structure, following it is considered a best practice for clarity and maintainability.\n",
    "\n",
    "**Example directory structure:**\n",
    "\n",
    "```\n",
    "my_etl_package/\n",
    "├── my_etl_package/              # Main package with modules/sub-packages\n",
    "│   ├── __init__.py              \n",
    "│   ├── load_data.py           \n",
    "│   ├── read_data.py             \n",
    "│   ├── transform_data.py      \n",
    "│   ├── write_data.py           \n",
    "│   ├── utils \n",
    "│   │   ├── __init__.py         \n",
    "│   │   ├── connect_db.py        \n",
    "│   │   └── fetch_files.py      \n",
    "├── test_my_etl_package/          # Test suite root\n",
    "│   ├── __init__.py\n",
    "│   ├── conftest.py             # Fixtures and global test setup\n",
    "│   ├── test_integration.py\n",
    "│   ├── test_performance.py\n",
    "│   └── test_utils/\n",
    "│       ├── __init__.py\n",
    "│       ├── test_connect_db.py\n",
    "│       └── test_fetch_files.py\n",
    "│\n",
    "├── setup.py\n",
    "├── main.py\n",
    "├── ... [other files for testing, formatting, documentation, etc.]\n",
    "└── tox.ini\n",
    "```\n",
    "Any test module or script inside the test directory can be run directly using the pytest command:\n",
    "```bash\n",
    "pytest test_my_etl_package/test_integration.py\n",
    "```\n",
    "#### Naming conventions:\n",
    "\n",
    "* Prefix all test folders and files with `test_`\n",
    "* Use descriptive but concise names: `test_fetch_files.py`, `test_integration.py`\n",
    "* Follow the same import structure in `__init__.py` files as in your main package\n",
    "\n",
    "#### 2.5. Writing Test Cases\n",
    "\n",
    "Let’s say you have a utility function that squares a number:\n",
    "\n",
    "```python\n",
    "# your_package/math_utils.py\n",
    "def square(x):\n",
    "    return x * x\n",
    "```\n",
    "\n",
    "#### Using `pytest`\n",
    "\n",
    "```python\n",
    "# test_utils/test_math_utils.py\n",
    "from your_package.math_utils import square\n",
    "\n",
    "def test_square():\n",
    "    assert square(2) == 4\n",
    "    assert square(5) == 25\n",
    "    assert square(-3) == 9\n",
    "```\n",
    "\n",
    "#### Using `unittest`\n",
    "\n",
    "```python\n",
    "# test_utils/test_math_utils_unittest.py\n",
    "import unittest\n",
    "from your_package.math_utils import square\n",
    "\n",
    "class TestMathUtils(unittest.TestCase):\n",
    "    def test_square(self):\n",
    "        self.assertEqual(square(2), 4)\n",
    "        self.assertEqual(square(5), 25)\n",
    "        self.assertEqual(square(-3), 9)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n",
    "```\n",
    "\n",
    "Both styles work effectively, and the choice depends on your project preference. `pytest` offers simpler syntax and advanced features, while `unittest` provides a structured, class-based approach.\n",
    "\n",
    "**Note**: Both `pytest` and `unittest` support custom assertions for `pandas`, `NumPy`, etc. See:\n",
    "\n",
    "* [Python unittest assertions](https://docs.python.org/3/library/unittest.html#test-cases)\n",
    "* [Pandas testing assertions](https://pandas.pydata.org/docs/reference/testing.html)\n",
    "\n",
    "\n",
    "#### 2.6. Key Testing Features\n",
    "The following features are embedded within any test modules or scripts:\n",
    "\n",
    "#### a) Fixtures\n",
    "\n",
    "Fixtures in `pytest` help prepare preconditions for tests; like sample data, database connections, or configuration. They improve code reuse and test readability.\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def sample_data():\n",
    "    return [1, 2, 3]\n",
    "\n",
    "def test_sample_data_length(sample_data):\n",
    "    assert len(sample_data) == 3\n",
    "```\n",
    "\n",
    "#### b) Markers\n",
    "\n",
    "Markers help categorise, skip, or handle tests conditionally.\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "import sys\n",
    "\n",
    "# This test is always skipped with the given reason\n",
    "@pytest.mark.skip(reason=\"Not implemented yet\")\n",
    "def test_not_ready():\n",
    "    assert False\n",
    "\n",
    "# This test is expected to fail due to a known bug (e.g. division by zero)\n",
    "# If it fails, pytest will mark it as expected; if it passes, pytest will warn\n",
    "@pytest.mark.xfail(reason=\"Known bug\")\n",
    "def test_bug_behavior():\n",
    "    assert 1 / 0 == 0\n",
    "\n",
    "# This test is skipped if the condition is True\n",
    "# Here, it will be skipped on non-Windows platforms\n",
    "@pytest.mark.skipif(sys.platform != \"win32\", reason=\"Runs only on Windows\")\n",
    "def test_windows_only_feature():\n",
    "    assert True\n",
    "```\n",
    "\n",
    "#### c) Temporary Files & Directories\n",
    "\n",
    "When testing file operations, use `pytest`'s `tmp_path` or `tmpdir` fixtures to work with temporary paths:\n",
    "\n",
    "```python\n",
    "def test_file_write(tmp_path):\n",
    "    test_file = tmp_path / \"output.txt\"\n",
    "    test_file.write_text(\"sample content\")\n",
    "    assert test_file.read_text() == \"sample content\"\n",
    "```\n",
    "\n",
    "These paths are automatically cleaned up after the test run.\n",
    "\n",
    "#### d) Setup and Teardown Methods\n",
    "\n",
    "Some tests require setting up resources before running (e.g., creating a database connection), and cleaning them afterward. These steps can be handled using **setup** and **teardown** methods.\n",
    "\n",
    "**Using `pytest` fixtures:**\n",
    "\n",
    "```python\n",
    "@pytest.fixture\n",
    "def db_connection():\n",
    "    conn = create_connection()\n",
    "    yield conn\n",
    "    conn.close()\n",
    "```\n",
    "\n",
    "**Using `unittest`:**\n",
    "\n",
    "```python\n",
    "import unittest\n",
    "\n",
    "class TestDB(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.conn = create_connection()\n",
    "\n",
    "    def tearDown(self):\n",
    "        self.conn.close()\n",
    "```\n",
    "\n",
    "These methods help ensure tests are isolated and don’t affect each other, especially when shared resources (like databases, files, or APIs) are involved. They also clean up unnecessary memory and resource usage after each test run.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "* **In `unittest`:**\n",
    "\n",
    "  * `setUp()` is called **before each test method** in the class to prepare the environment (e.g., open DB connections).\n",
    "  * `tearDown()` is called **after each test method** to clean up (e.g., close connections, release memory).\n",
    "  * These methods are automatically run for every test, regardless of whether the test needs the resource or not.\n",
    "\n",
    "* **In `pytest`:**\n",
    "\n",
    "  * `@pytest.fixture` functions run **before each test** that explicitly uses the fixture (by passing it as a parameter).\n",
    "  * Code placed **after `yield`** in the fixture acts as the teardown; it runs **after the test finishes**.\n",
    "  * Fixtures give more control: they can be shared, scoped (per function/module/session), and reused across multiple tests or files.\n",
    "\n",
    "This helps ensure test isolation and avoids shared state side effects.\n",
    "\n",
    "#### e) Mocking\n",
    "\n",
    "Mocking is used to simulate external dependencies or environment conditions, allowing tests to run in isolation and reliably without needing real external resources.\n",
    "\n",
    "In this example, we mock environment variables using `patch.dict` to test that `PostgresConnector` utility module from our package creates the correct database connection string without requiring actual environment setup, but mocking it:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pytest\n",
    "from my_etl_package.utils import PostgresConnector\n",
    "from unittest.mock import patch\n",
    "from sqlalchemy.engine import Engine\n",
    "\n",
    "\n",
    "# Connector to the database\n",
    "connector = PostgresConnector()\n",
    "\n",
    "\n",
    "def test_get_db_connection():\n",
    "    \"\"\"\n",
    "    Test that PostgresConnector generates the correct SQLAlchemy engine\n",
    "    when all required environment variables are present.\n",
    "    \"\"\"\n",
    "    # Load env vars from the connector\n",
    "    ENV_VARS = {\n",
    "        \"DB_HOST\": connector.host,\n",
    "        \"DB_NAME\": connector.database,\n",
    "        \"DB_USER\": connector.user,\n",
    "        \"DB_PASSWORD\": connector.password,\n",
    "        \"DB_PORT\": connector.port,\n",
    "    }\n",
    "\n",
    "    with patch.dict(os.environ, ENV_VARS):\n",
    "        engine = connector.get_db_connection()\n",
    "\n",
    "        # Assert type\n",
    "        assert isinstance(engine, Engine)\n",
    "\n",
    "        # Assert connection string\n",
    "        actual = engine.url.render_as_string(hide_password=False)\n",
    "        expected = f\"postgresql://{connector.user}:{connector.password}@{connector.host}:{connector.port}/{connector.database}\"\n",
    "        assert actual == expected\n",
    "        \n",
    "```\n",
    "\n",
    "****Notes:****\n",
    "\n",
    "* The `patch.dict(os.environ, ENV_VARS)` temporarily **overrides environment variables** just for this test.\n",
    "* This allows testing the behavior of `get_db_connection()` **without relying on real environment setup**.\n",
    "* Mocking environment variables ensures tests are **deterministic, isolated, and safe to run anywhere**.\n",
    "* The patch only applies within the `with` block scope, so it doesn't affect other tests or the global environment.\n",
    "\n",
    "Mocking lets you control the return values of functions and track how they're called, enabling precise unit tests without invoking real dependencies.\n",
    "\n",
    "#### f) Performance Benchmarking\n",
    "\n",
    "Using the `pytest-benchmark` plugin, you can test how efficiently your code runs:\n",
    "\n",
    "```python\n",
    "def test_sorting_speed(benchmark):\n",
    "    data = list(range(1000, 0, -1))  # Create a reversed list of 1000 numbers\n",
    "    benchmark(sorted, data)           # Benchmark the built-in sorted function on this data\n",
    "```\n",
    "\n",
    "* `benchmark` is a pytest fixture that runs the given callable multiple times to measure performance.\n",
    "* The first argument after `benchmark` is the callable (`sorted`), and the rest are arguments passed to it (`data`).\n",
    "* This runs `sorted(data)` repeatedly and reports the timing statistics.\n",
    "\n",
    "If you wanted to do the same with the decorator style, it would look like:\n",
    "\n",
    "```python\n",
    "def test_sorting_speed_decorator(benchmark):\n",
    "    data = list(range(1000, 0, -1))\n",
    "\n",
    "    @benchmark\n",
    "    def run_sort():\n",
    "        sorted(data)\n",
    "```\n",
    "Both are valid and produce similar benchmarking results.\n",
    "\n",
    "This is particularly useful when optimising data transformations or algorithms for large-scale use.\n",
    "\n",
    "#### 2.7. Pytest Configuration File (`conftest.py`)\n",
    "\n",
    "The `conftest.py` file is used by pytest to set up configuration and fixtures shared across multiple test modules. In this example, it loads environment variables from a `.env` file located at the root of your project directory. This setup ensures that environment-dependent configurations, such as database credentials or API keys, are available during test runs.\n",
    "\n",
    "The environment variables are loaded using the `python-dotenv` package, with the `.env` file path explicitly resolved relative to the location of the `conftest.py` file:\n",
    "\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load .env file from the root directory of the project\n",
    "load_dotenv(dotenv_path=Path(__file__).resolve().parents[1] / \".env\")\n",
    "```\n",
    "\n",
    "Here, `Path(__file__).resolve().parents[1]` navigates two levels up from the `conftest.py` file to locate the root directory, where the `.env` file is stored. This approach ensures consistent loading of environment variables regardless of the current working directory when tests are executed.\n",
    "\n",
    "#### 2.8. Running Tests\n",
    "\n",
    "You can run all your tests using the following commands in the `top-level/parent` directory of the package using the `CLI`:\n",
    "\n",
    "```bash\n",
    "pytest               # discovers and runs all tests\n",
    "pytest -v            # verbose output\n",
    "pytest -k \"pattern\"  # run tests matching pattern\n",
    "pytest --maxfail=2   # stop after two failures\n",
    "```\n",
    "\n",
    "To run across Python versions using `tox` use the following commands in the `top-level/parent` directory of the package using the `CLI`:\n",
    "\n",
    "```bash\n",
    "tox\n",
    "```\n",
    "\n",
    "Your `tox.ini` would look like:\n",
    "\n",
    "```ini\n",
    "[tox]\n",
    "envlist = py310, py311\n",
    "\n",
    "[testenv]\n",
    "deps =\n",
    "    pytest\n",
    "    python-dotenv\n",
    "    sqlalchemy\n",
    "    psycopg2-binary\n",
    "    pytest-benchmark\n",
    "commands =\n",
    "    pytest --doctest-modules\n",
    "```\n",
    "\n",
    "This configuration:\n",
    "\n",
    "* Creates virtual environments for Python 3.10 and 3.11\n",
    "* Installs necessary dependencies for the test suite\n",
    "* Runs all `pytest` tests and also executes **doctests**, which are embedded in module-level docstrings using the `--doctest-modules` flag\n",
    "\n",
    "#### Notes:\n",
    "\n",
    "* **`pytest`** can run both standard test scripts and doctests. So even if your code uses `unittest`, you can still run those tests via `pytest` since it’s compatible with `unittest`-style tests. `pytest` will pick up and run `unittest` test cases by default.\n",
    "* **`doctest`** allows you to validate example code embedded in your documentation. These are often used in function or class docstrings to demonstrate expected usage and output.\n",
    "\n",
    "This setup enables a robust, scalable, and maintainable testing strategy for your Python package. Whether you choose `pytest`, `unittest`, or both, the key is to stay consistent and prioritize clarity and coverage. Let your tests guide your development, not just validate it afterward.\n",
    "\n",
    "Testing is not just a chore, it’s a superpower. With a proper testing framework in place, you can:\n",
    "\n",
    "- Avoid regressions\n",
    "- Ship faster with confidence\n",
    "- Build reliable, scalable, maintainable packages\n",
    "\n",
    "Start small. Cover critical paths first. Add more as you go. The tools are powerful and the payoff is huge.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Increasing Package Quality\n",
    "\n",
    "In [**Part 1**](https://medium.com/@khhaledahmaad/some-advanced-software-engineering-principles-for-writing-clean-reusable-python-code-part-1-cc518b97e422), we discussed documentation, type annotations, and enforcing code standards using linters in line with the [PEP 8 – Style Guide for Python Code](https://peps.python.org/pep-0008/). Please refer to sections 2, 3, and 12 for a recap.\n",
    "\n",
    "You can apply these practices manually or automate them using tools like:\n",
    "\n",
    "* [`pyment`](https://github.com/dadadel/pyment): to generate docstrings\n",
    "* [`monkeytype`](https://github.com/Instagram/MonkeyType): to infer and apply type hints\n",
    "* [`flake8`](https://flake8.pycqa.org): to check Python code style and standards\n",
    "\n",
    "In this part, we’ll include a **configuration file** for `flake8` to automatically check all scripts and modules in the project. This ensures consistent formatting and helps catch style violations across the package. Below is a example configuration file (`setup.cfg`) in the top-level directory (same location as `setup.py`):\n",
    "\n",
    "```ini\n",
    "[flake8]\n",
    "\n",
    "ignore =\n",
    "    E501\n",
    "\n",
    "exclude =\n",
    "    .git,\n",
    "    __pycache__,\n",
    "    build,\n",
    "    dist,\n",
    "    .tox,\n",
    "    .eggs,\n",
    "    my_etl_package.egg-info\n",
    "    .benchmarks,\n",
    "    .pytest_cache\n",
    "\n",
    "per-file-ignores =\n",
    "    __init__.py: F401\n",
    "\n",
    "```\n",
    "\n",
    "With this configuration, running `flake8` in the terminal from the top-level directory will recursively check all relevant Python files while skipping unwanted directories, files, and style warnings.\n",
    "\n",
    "* **ignore**: Specifies which error codes to skip reporting. In this case, it tells flake8 to ignore warnings about lines being too long (E501).\n",
    "\n",
    "* **exclude**: Lists files and directories that flake8 should completely skip when checking your code, such as version control folders, caches, build output, test and package metadata.\n",
    "\n",
    "* **per-file-ignores**: Defines specific warnings or errors to ignore but only for certain files. Here, it tells flake8 not to warn about unused imports in all `__init__.py` files, which is common since those files often import modules to make them available without using them directly.\n",
    "\n",
    "You can check individual files using the following commands in the `top-level/parent` directory of the package using the `CLI`:\n",
    "```bash\n",
    "flake8 <package/module.py>\n",
    "```\n",
    "\n",
    "To run flake8 to do checks for all the files based on the configuration in `setup.cfg`, use the following commands in the `top-level/parent` directory of the package using the `CLI`:\n",
    "```bash\n",
    "flake8\n",
    "```\n",
    "__Example Output:__\n",
    "\n",
    "```bash\n",
    ".\\my_etl_package\\transform_data.py:14:80: E501 line too long (81 > 79 characters)\n",
    ".\\my_etl_package\\transform_data.py:19:80: E501 line too long (90 > 79 characters)\n",
    ".\\my_etl_package\\transform_data.py:20:80: E501 line too long (85 > 79 characters)\n",
    ".\\my_etl_package\\transform_data.py:24:80: E501 line too long (87 > 79 characters)\n",
    ".\\my_etl_package\\transform_data.py:26:80: E501 line too long (92 > 79 characters)\n",
    ".\\my_etl_package\\utils\\connect_db.py:14:80: E501 line too long (95 > 79 characters)\n",
    ".\\my_etl_package\\utils\\connect_db.py:26:80: E501 line too long (84 > 79 characters)\n",
    ".\\my_etl_package\\utils\\connect_db.py:32:80: E501 line too long (83 > 79 characters)\n",
    ".\\my_etl_package\\utils\\connect_db.py:34:80: E501 line too long (85 > 79 characters)\n",
    ".\\my_etl_package\\utils\\connect_db.py:48:80: E501 line too long (102 > 79 characters)\n",
    ".\\test_my_etl_package\\test_performance.py:40:80: E501 line too long (83 > 79 characters)\n",
    ".\\test_my_etl_package\\test_utils\\test_connect_db.py:34:80: E501 line too long (127 > 79 characters)\n",
    ".\\test_my_etl_package\\test_utils\\test_connect_db.py:50:80: E501 line too long (84 > 79 characters)\n",
    "```\n",
    "After adding the following line and running the `flake8` command again will return nothing as all the standards configured for our code are satisfied:\n",
    "\n",
    "```ini\n",
    "ignore =\n",
    "    E501\n",
    "```\n",
    "As simple as that, `flake` it, fix it, and `flake` it again until there’s nothing left to `flake`!\n",
    "\n",
    "To learn more about some of these error codes mentioned here, please follow this [`PEP8 Error Codes`](https://pep8.readthedocs.io/en/release-1.7.x/intro.html#error-codes).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Publishing your Package \n",
    "\n",
    "__So You Built a Python Package, Tested and Improved it… Now What?__\n",
    "\n",
    "You’ve written the code; you’ve tested it until your terminal cried; you’ve improved the quality until even your linter gave you a thumbs up. But now what?\n",
    "\n",
    "Let’s be honest, if you're the only one using your beautiful piece of software, then congratulations, you’ve just made a very fancy personal tool. But what if your package could be *the next pandas*, *the next requests*, *the next... whatever solves a real problem*?\n",
    "\n",
    "Welcome to the final and often forgotten boss level of package development: **making it open-source ready**. That means sharing it in a way that’s usable, reproducible, and maintainable by others, not just future-you at 2am in three months.\n",
    "\n",
    "Here’s a walk-through of the most essential files and steps you need before you can proudly `pip install` your package from `PyPI`, and maybe, just maybe, watch your GitHub repo gain some stars.\n",
    "\n",
    "#### What Is PyPI?\n",
    "\n",
    "[**PyPI**](https://pypi.org/), short for the *Python Package Index*, is the **official third-party software repository** for Python. It’s where developers publish open-source Python packages so others can install them easily using `pip`. `pip` is Python’s official package manager, and yes, it’s a command-line tool, but it’s specifically used for installing and managing Python packages from sources like `PyPI`.\n",
    "\n",
    "Whether it’s `pandas`, `numpy`, or that oddly named CLI tool that turns YAML into poetry, it probably lives on `PyPI`.\n",
    "\n",
    "#### Why Use PyPI?\n",
    "\n",
    "* Makes your package **installable with one command**:\n",
    "\n",
    "  ```bash\n",
    "  pip install your-package-name\n",
    "  ```\n",
    "\n",
    "* Gives your project **visibility** in the Python community\n",
    "\n",
    "* Enables **versioned releases** and proper dependency management\n",
    "\n",
    "* Allows others to **integrate, extend, and contribute** to your work\n",
    "\n",
    "In short, if you want your project to be more than just a GitHub repo, publishing it on `PyPI` is the way to go to make it a open-source tool for the world.\n",
    "\n",
    "Below are some of the key steps you might need to follow before you publish your package to `PyPI`.\n",
    "\n",
    "That’s a solid start! Here's a lightly refined and polished version of your **Step 0** section, keeping the tone professional yet developer-friendly, and improving the flow slightly while preserving your intent:\n",
    "\n",
    "\n",
    "#### Step 0: Start With a Cookie (Template)\n",
    "\n",
    "Before diving into the individual files, let’s not reinvent the wheel. Use [`cookiecutter`](https://cookiecutter.readthedocs.io/en/latest/), a command-line utility that helps you generate a professional Python package scaffold with all the essential pieces baked in.\n",
    "\n",
    "Instead of manually creating `setup.py`, `README.md`, `tests/`, and more, Cookiecutter gives you a clean, modular structure right out of the box. All you need to do is copy your fancy package code — including sub-packages, modules, and tests, into the generated template.\n",
    "\n",
    "That’s it, no more fiddling with boilerplate. Of course, you’ll likely need to tweak some of the generated files to match your codebase and project goals, but the heavy lifting is already done.\n",
    "\n",
    "To get started, run the following in the project's top-level directory:\n",
    "\n",
    "```bash\n",
    "pip install cookiecutter\n",
    "cookiecutter https://github.com/audreyfeldroy/cookiecutter-pypackage\n",
    "```\n",
    "\n",
    "Follow the prompts and you’ll get a clean, production-ready project structure with many of the files we’re about to talk about.\n",
    "\n",
    "#### 4.1. Key Project Files (And What They’re For)\n",
    "\n",
    "These files aren’t just “nice to have”, they’re essential for a professional, open-source-ready project. A brief description of all these files are added below (please see these files in the GitHub repository added in the source code for more details and examples). While the files list may not be exhausted, the following are the basics to get started (please use a `cookiecutter` template for a more modern package structure with all possible files included automatically).\n",
    "\n",
    "#### a) `CONTRIBUTING.md`: How Others Can Help\n",
    "\n",
    "Outlines how contributors should get started. Include:\n",
    "\n",
    "* Steps to clone and set up the environment\n",
    "* Code style guidelines\n",
    "* How to run tests and submit pull requests\n",
    "\n",
    "#### b)  `LICENSE.md`: Legal Permissions\n",
    "\n",
    "Specifies how your code can be used. Popular choices for open-source:\n",
    "\n",
    "* **MIT License**: Simple and permissive\n",
    "* **Apache License 2.0**: Permissive with patent protection\n",
    "* **GNU General Public License v3.0**: Requires derived works to be open-source\n",
    "\n",
    "Place this file in the root directory. GitHub detects it automatically. Or you can add a license during GitHub repository creation.\n",
    "\n",
    "#### c) `MANIFEST.in`: Package Non-Python Files\n",
    "\n",
    "Ensures required data (e.g. README, configs, assets) are included during distribution.\n",
    "\n",
    "Example:\n",
    "\n",
    "```txt\n",
    "include CONTRIBUTING.md\n",
    "include HISTORY.md\n",
    "include LICENSE\n",
    "include README.md\n",
    "```\n",
    "\n",
    "#### d) `README.md`: The First Impression\n",
    "\n",
    "Explains what the project does, how to install it, and how to use it.\n",
    "Essential sections:\n",
    "\n",
    "* Overview\n",
    "* Installation\n",
    "* Basic usage\n",
    "* Contribution guidelines\n",
    "\n",
    "#### e) `HISTORY.md`: What Changed\n",
    "\n",
    "Keeps track of version history. Helps users understand what's new, fixed, or removed in each release.\n",
    "\n",
    "Format:\n",
    "\n",
    "```md\n",
    "# Changelog\n",
    "\n",
    "All notable changes to this project will be documented in this file.\n",
    "\n",
    "## [1.0.0] - 2025-06-03\n",
    "### Added\n",
    "- Initial release of `my_etl_package` package.\n",
    "- Included core ETL pipeline functionality.\n",
    "- Added subpackage `my_etl_package`.utills` with utility functions.\n",
    "- Added dependencies: numpy, pandas, sqlalchemy, psycopg2-binary, python-dotenv.\n",
    "- Configured basic setup.py, tox.ini, setup.cfg for testing and linting.\n",
    "```\n",
    "\n",
    "#### f) `.env` and `.env.example`: Keep Secrets Safe\n",
    "\n",
    "Your `.env` file contains sensitive environment variables and must **not** be committed.\n",
    "\n",
    "Instead:\n",
    "\n",
    "* Create a `.env.example` with placeholder values\n",
    "* Add `.env` to `.gitignore`\n",
    "\n",
    "#### 4.2. Uploading to GitHub\n",
    "\n",
    "#### Why Upload to GitHub?\n",
    "\n",
    "Uploading your code to GitHub helps you:\n",
    "\n",
    "* **Keep track of changes** to your code (version control)\n",
    "* **Collaborate** with others or get help\n",
    "* **Showcase your project** to the community (especially if you publish to PyPI)\n",
    "* **Link your code** on the PyPI page (so users can read it or contribute)\n",
    "\n",
    "It’s not required for PyPI, but **strongly recommended**.\n",
    "\n",
    "#### Steps to Upload a Python Project to GitHub\n",
    "\n",
    "1. **Create a new repo on GitHub**\n",
    "   Go to [https://github.com/new](https://github.com/new), give it a name, and click \"Create repository\". \n",
    "   \n",
    "__Note:__ Do not forget to add a `.gitignore` for Python and `license` file while creating a new repo. This saves extra hassle for adding all the files for git to ignore and copying a license as the files added through Github mostly do the jobs. \n",
    "\n",
    "2. **Initialize Git locally (if not already)**\n",
    "   In the project's top-level directory:\n",
    "\n",
    "```bash\n",
    "   git init\n",
    "```\n",
    "\n",
    "3. **Connect to GitHub**\n",
    "\n",
    "```bash\n",
    "   git remote add origin https://github.com/your-username/my_etl_package.git\n",
    "```\n",
    "\n",
    "4. **Pull from GitHub**\n",
    "This will pull any additional files like .gitignore, license files, etc. to your local repository without overwriting any local files.\n",
    "\n",
    "```bash\n",
    "    git pull origin main\n",
    "```\n",
    "\n",
    "5. **Add all your files**\n",
    "\n",
    "```bash\n",
    "   git add .\n",
    "   git commit -m \"Initial commit\"\n",
    "```\n",
    "\n",
    "6. **Rename the local branch to `main` to match GitHub’s default**\n",
    "```bash\n",
    "   git branch -M main\n",
    "```\n",
    "\n",
    "7. **Push your code**\n",
    "\n",
    "```bash\n",
    "   git push -u origin main\n",
    "```\n",
    "\n",
    "__Note:__ The above steps require an `SSH` key to connect to GitHub using `CLI`. To create and add an `SSH` key to GitHub, please follow this official guidance:\n",
    "[Generating a new SSH key and adding it to the ssh-agent](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent)\n",
    "\n",
    "If you have [GitHub Desktop](https://github.com/apps/desktop) installed, you can use it to clone repositories and not deal with `SSH` keys.\n",
    "\n",
    "#### 4.3. Uploading to PyPI\n",
    "Before you can publish your code to `PyPI`, you must build the distribution for your package.\n",
    "\n",
    "#### What Does \"Build the Distribution\" Mean, and Why Is It Necessary?\n",
    "\n",
    "When we say \"build\" in the context of publishing a Python package, we’re referring to **creating a distributable version** of your code that tools like `pip` can understand and install.\n",
    "\n",
    "This step transforms your raw project files into a **packaged format**, like a `.tar.gz` source archive or a `.whl` (wheel) binary, which can then be uploaded to **PyPI** and installed via `pip`.\n",
    "\n",
    "\n",
    "#### Why Do You Need to Build?\n",
    "\n",
    "1. **`pip` installs built packages**\n",
    "\n",
    "`pip` doesn’t clone your repo or read your raw `.py` files, it installs from a `.whl` or `.tar.gz` found on PyPI.\n",
    "\n",
    "2. **Uploading to PyPI requires built files**\n",
    "\n",
    "[`twine`](https://twine.readthedocs.io/en/stable/) (a utility for publishing Python packages on PyPI) doesn’t upload your code directly, it uploads the package files in `/dist`.\n",
    "\n",
    "3. **Each build is version-specific**\n",
    "\n",
    "If you update your code or bump the version, you must rebuild so the distribution matches the new state.\n",
    "\n",
    "4. **Packaging tools use metadata**\n",
    "\n",
    "Building includes project metadata (`setup.py` or `pyproject.toml`, dependencies, etc.) which `pip` needs. Make sure the package name doesn’t conflict with existing packages already published and available.\n",
    "\n",
    "#### What Happens If You Skip It?\n",
    "\n",
    "* You’ll try to upload a package that doesn’t match your current version, and PyPI will reject it.\n",
    "* Your new code won’t be included — users will install an outdated or broken package.\n",
    "* Your upload process (`twine`) will literally have nothing to send.\n",
    "\n",
    "#### a) Uploading to TestPyPI (Dry Run)\n",
    "\n",
    "Before going live, test your distribution on [TestPyPI](https://test.pypi.org/). This lets you catch issues without releasing to the real PyPI. I must register an account with verified email and 2FA authentication method to create an API token, which is required to upload your code to TestPyPI using twine.\n",
    "\n",
    "#### Step-by-Step: \n",
    "Run the following commands In the project's top-level directory:\n",
    "\n",
    "1. **Build the distribution:**\n",
    "\n",
    "```bash\n",
    "python setup.py sdist bdist_wheel\n",
    "```\n",
    "\n",
    "#### So What’s Actually Being Built?\n",
    "\n",
    "When you run:\n",
    "\n",
    "```bash\n",
    "python setup.py sdist bdist_wheel\n",
    "```\n",
    "\n",
    "You get:\n",
    "\n",
    "| File Type                           | Purpose                                                      |\n",
    "| ----------------------------------- | ------------------------------------------------------------ |\n",
    "| `dist/my_etl_package-1.0.0.tar.gz`           | Source distribution, like a zipped version of your codebase |\n",
    "| `dist/my_etl_package-1.0.0-py3-none-any.whl` | Wheel file, a faster-to-install binary format used by pip   |\n",
    "\n",
    "2. **Check it’s valid:**\n",
    "\n",
    "```bash\n",
    "twine check dist/*\n",
    "```\n",
    "\n",
    "3. **Upload to TestPyPI:**\n",
    "\n",
    "```bash\n",
    "twine upload --repository-url https://test.pypi.org/legacy/ -u __token__ -p \"<your_api_token>\" --verbose dist/*\n",
    "```\n",
    "Simply replace the placeholder (`<your_api_token>`) with your API Token. If there any errors and cannot be uploaded, e.g., due to an invalid classifier in your `setup.py` file, the `--verbose` argument will show exactly what's wrong. If the upload is successful, the command will show you the link where your package is uploaded.\n",
    "\n",
    "4. **Install from TestPyPI:**\n",
    "\n",
    "```bash\n",
    "pip install -i https://test.pypi.org/simple/ my-etl-package==1.0.0 --extra-index-url https://pypi.org/simple/\n",
    "```\n",
    "\n",
    "`--extra-index-url https://pypi.org/simple/` this extra argument will ensure any additional Python dependencies needed for installing your package will be downloaded from `PyPI` if they are not available from `TestPyPI`. `TestPyPI` does not mirror the full `PyPI` index, so many common packages (like pandas) aren’t there. \n",
    "\n",
    "#### b) Uploading to PyPI (Production)\n",
    "\n",
    "Once the test goes well, you’re ready for the real deal.\n",
    "\n",
    "1. **Register on PyPI:**\n",
    "   [https://pypi.org/account/register/](https://pypi.org/account/register/)\n",
    "2. Verify your email, and add a 2FA authentication method to create an API token, which is required to upload your code to TPyPI using twine.\n",
    "\n",
    "2. **Upload:**\n",
    "\n",
    "```bash\n",
    "twine upload -u __token__ -p \"<your_api_token>\" --verbose dist/*\n",
    "```\n",
    "Simply replace the placeholder (`<your_api_token>`) with your API Token. If there any errors and cannot be uploaded, e.g., due to an invalid classifier in your `setup.py` file, the `--verbose` argument will show exactly what's wrong. If the upload is successful, the command will show you the link where your package is uploaded.\n",
    "\n",
    "\n",
    "#### c) Automating with a Makefile\n",
    "\n",
    "Why type ten commands when one will do? Here's a `Makefile` to automate everything:\n",
    "\n",
    "```makefile\n",
    ".PHONY: build test upload upload-test clean\n",
    "\n",
    "build:\n",
    "\tpython setup.py sdist bdist_wheel\n",
    "\n",
    "check:\n",
    "\ttwine check dist/*\n",
    "\n",
    "upload:\n",
    "\ttwine upload -u __token__ -p \"<your_api_token>\" --verbose dist/*\n",
    "\n",
    "upload-test:\n",
    "\ttwine upload --repository-url https://test.pypi.org/legacy/ -u __token__ -p \"<your_api_token>\" --verbose dist/*\n",
    "\n",
    "clean:\n",
    "\tpython -c \"import shutil, glob; [shutil.rmtree(d) for d in glob.glob('dist')]\"\n",
    "\tpython -c \"import shutil, glob; [shutil.rmtree(d) for d in glob.glob('build')]\"\n",
    "\tpython -c \"import shutil, glob; [shutil.rmtree(d) for d in glob.glob('*.egg-info')]\"\n",
    "\n",
    "all: clean build check\n",
    "```\n",
    "\n",
    "Put this file in your project root as `Makefile` (no extension).\n",
    "\n",
    "__Note:__ Please ensure that command lines in the `Makefile` start with tabs, not spaces. > Also, do not commit the `Makefile` to GitHub if it contains your TestPyPI/PyPI API tokens. Either add it to `.gitignore` or replace the token with a placeholder.\n",
    "\n",
    "#### To use it: Run the following commands in the package's top-level directory\n",
    "\n",
    "Before you can use a Makefile, you need to make sure that `make` is already installed. If it’s not, you can either download it from the official site or install it via Conda:\n",
    "\n",
    "```bash\n",
    "make --version\n",
    "conda install -c conda-forge make\n",
    "```\n",
    "\n",
    "Once you have `make` installed, you can run the following based on the configuration of your `makefile`:\n",
    "```bash\n",
    "make all         # Clean, build, and check\n",
    "make upload      # Upload to PyPI\n",
    "make upload-test # Upload to TestPyPI\n",
    "make clean       # Remove build artifacts\n",
    "```\n",
    "\n",
    "#### 4.4. Managing Version Numbers\n",
    "\n",
    "#### Understanding Version Numbers (Semantic Versioning)\n",
    "\n",
    "Python packages usually use **semantic versioning**, which uses a `MAJOR.MINOR.PATCH` format like `1.2.3`. Each number means something specific:\n",
    "\n",
    "* **Major version** (first number):\n",
    "  Increase this when you make big changes that break how the package works or introduce completely new features.\n",
    "  Example: `1.0.0` becomes `2.0.0`\n",
    "\n",
    "* **Minor version** (second number):\n",
    "  Increase this when you add small new features or improvements that don’t break anything.\n",
    "  Example: `1.2.0` becomes `1.3.0`\n",
    "\n",
    "* **Patch version** (third number):\n",
    "  Increase this when you fix bugs or make tiny changes.\n",
    "  Example: `1.2.3` becomes `1.2.4`\n",
    "\n",
    "#### Tip:\n",
    "\n",
    "Every time you make a change and want to release it, bump the version number. Then rebuild the package and upload it again.\n",
    "\n",
    "#### Managing Version Numbers Automatically with `bumpversion`\n",
    "\n",
    "Manually editing your version in multiple places (`setup.py`, `__init__.py`, `HISTORY.md`, etc.) can get annoying, and error-prone. That’s where [`bumpversion`](https://github.com/c4urself/bump2version) comes in.\n",
    "\n",
    "It automatically updates version numbers across your project files in a consistent and trackable way, making releases clean and efficient.\n",
    "\n",
    "#### Installation\n",
    "\n",
    "```bash\n",
    "pip install bump2version\n",
    "```\n",
    "\n",
    "> ⚠️ Note: The command is still `bumpversion` even though the package is called `bump2version`.\n",
    "\n",
    "#### Step 1: Configure `.bumpversion.cfg`\n",
    "\n",
    "Create a `.bumpversion.cfg` file in your project root:\n",
    "\n",
    "```ini\n",
    "[bumpversion]\n",
    "current_version = 1.0.0\n",
    "commit = True\n",
    "tag = True\n",
    "\n",
    "[bumpversion:file:setup.py]\n",
    "```\n",
    "\n",
    "This tells `bumpversion` what your current version is, where to update it, and whether to auto-commit and tag.\n",
    "\n",
    "#### Step 2: Bump the Version\n",
    "\n",
    "Use one of these commands based on what you want to change:\n",
    "\n",
    "```bash\n",
    "bumpversion patch   # 0.1.0 → 0.1.1\n",
    "bumpversion minor   # 0.1.1 → 0.2.0\n",
    "bumpversion major   # 0.2.0 → 1.0.0\n",
    "```\n",
    "\n",
    "It will:\n",
    "\n",
    "* Update version numbers in all configured files\n",
    "* Commit the changes\n",
    "* Tag the commit (e.g. `v1.0.0`)\n",
    "\n",
    "__Note:__ Bumpversion command only will work if the git remote repository is up-to-date. Therefore, please make sure that you commit any changes before bumping the version.\n",
    "\n",
    "#### Best Practice\n",
    "\n",
    "Run `make all` and `make upload` right after bumping to build and release the new version, also `push` the changes to GitHub.\n",
    "\n",
    "Example:\n",
    "\n",
    "```bash\n",
    "bumpversion patch\n",
    "make all\n",
    "make upload\n",
    "git push origin main\n",
    "git push origin --tags\n",
    "```\n",
    "\n",
    "#### 4.5. How to Remove a Package from PyPI/TestPyPI\n",
    "\n",
    "PyPI **does not allow deleting entire packages** after upload — this is to prevent breaking dependencies for others.\n",
    "\n",
    "However, you **can delete a specific release version**:\n",
    "\n",
    "1. Go to [https://pypi.org/manage/projects/](https://pypi.org/manage/projects/)\n",
    "2. Click the version dropdown → Manage version\n",
    "3. Scroll to the bottom → Delete this version\n",
    "\n",
    "Be cautious, deleted versions cannot be re-uploaded unless you bump the version number.\n",
    "\n",
    "You can follow the same steps above for `TestPyPI` by going to the `TestPyPI` website ([https://test.pypi.org/manage/projects/](https://test.pypi.org/manage/projects/)).\n",
    "\n",
    "For full deletion (rare and requires good reasons), email: `admin@pypi.org`\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Source Code\n",
    "[My ETL Package](https://github.com/khhaledahmaad/my_etl_package)\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Conclusion \n",
    "\n",
    "Building a Python package from scratch is more than just writing code, it’s about creating reusable, maintainable, and professional-grade software. From structuring modules and sub-packages to implementing robust testing strategies, applying code quality standards, and finally publishing to GitHub and PyPI, each step reinforces best practices in software engineering.\n",
    "\n",
    "By following the principles outlined in this guide, you ensure that your package is not only functional but also scalable, reliable, and user-friendly. Proper testing, modular design, and adherence to Python standards like PEP 8 make your code easier to maintain and extend, while publishing to PyPI and GitHub allows others to benefit from your work, fostering collaboration and open-source contribution.\n",
    "\n",
    "Ultimately, creating your own Python package transforms repetitive tasks into clean, reusable tools, empowering you to focus on solving problems rather than rewriting code. Whether for personal projects or professional applications, the skills and practices covered here are an investment in long-term code quality, efficiency, and impact.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. References\n",
    "\n",
    "1. Python Software Foundation, 2023. *The Python Tutorial.* \\[online] Available at: [https://docs.python.org/3/tutorial/](https://docs.python.org/3/tutorial/) \\[Accessed 3 April 2025].\n",
    "\n",
    "2. Python Software Foundation, 2023. *Python Modules.* \\[online] Available at: [https://docs.python.org/3/tutorial/modules.html](https://docs.python.org/3/tutorial/modules.html) \\[Accessed 4 April 2025].\n",
    "\n",
    "3. Python Software Foundation, 2023. *Packages.* \\[online] Available at: [https://docs.python.org/3/tutorial/modules.html#packages](https://docs.python.org/3/tutorial/modules.html#packages) \\[Accessed 5 May 2025].\n",
    "\n",
    "4. Python Software Foundation, 2023. *The `__init__.py` file.* \\[online] Available at: [https://docs.python.org/3/reference/import.html#packages](https://docs.python.org/3/reference/import.html#packages) \\[Accessed 6 May 2025].\n",
    "\n",
    "5. Python Software Foundation, 2023. *The Python Standard Library: unittest — Unit testing framework.* \\[online] Available at: [https://docs.python.org/3/library/unittest.html](https://docs.python.org/3/library/unittest.html) \\[Accessed 2 June 2025].\n",
    "\n",
    "6. Python Software Foundation, 2023. *Distutils: Writing the Setup Script.* \\[online] Available at: [https://docs.python.org/3.11/distutils/setupscript.html](https://docs.python.org/3.11/distutils/setupscript.html) \\[Accessed 3 June 2025].\n",
    "\n",
    "7. Python Software Foundation, 2023. *Installing Python Modules.* \\[online] Available at: [https://packaging.python.org/en/latest/tutorials/installing-packages/](https://packaging.python.org/en/latest/tutorials/installing-packages/) \\[Accessed 4 July 2025].\n",
    "\n",
    "8. Python Software Foundation, 2023. *Packaging Python Projects.* \\[online] Available at: [https://packaging.python.org/en/latest/tutorials/packaging-projects/](https://packaging.python.org/en/latest/tutorials/packaging-projects/) \\[Accessed 5 July 2025].\n",
    "\n",
    "9. Python Software Foundation, 2023. *PyPI — the Python Package Index.* \\[online] Available at: [https://pypi.org/](https://pypi.org/) \\[Accessed 3 August 2025].\n",
    "\n",
    "10. Python Software Foundation, 2023. *Using Python on Different Platforms.* \\[online] Available at: [https://docs.python.org/3/using/index.html](https://docs.python.org/3/using/index.html) \\[Accessed 4 August 2025].\n",
    "\n",
    "11. Python Software Foundation, 2023. *doctest — Test interactive Python examples.* \\[online] Available at: [https://docs.python.org/3/library/doctest.html](https://docs.python.org/3/library/doctest.html) \\[Accessed 5 August 2025].\n",
    "\n",
    "12. Python Software Foundation, 2023. *Absolute and Relative Imports.* \\[online] Available at: [https://docs.python.org/3/reference/import.html#package-relative-imports](https://docs.python.org/3/reference/import.html#package-relative-imports) \\[Accessed 10 August 2025].\n",
    "\n",
    "13. Python Software Foundation, 2023. *Python Style Guide (PEP 8).* \\[online] Available at: [https://peps.python.org/pep-0008/](https://peps.python.org/pep-0008/) \\[Accessed 15 August 2025].\n",
    "\n",
    "14. TestPyPI, 2023. *TestPyPI — the Python Package Index for testing.* \\[online] Available at: [https://test.pypi.org/](https://test.pypi.org/) \\[Accessed 20 August 2025].\n",
    "\n",
    "15. Twine Project, 2023. *Twine Documentation.* \\[online] Available at: [https://twine.readthedocs.io/en/stable/](https://twine.readthedocs.io/en/stable/) \\[Accessed 3 September 2025].\n",
    "\n",
    "---\n",
    "\n",
    "### Author: [Khaled Ahmed](https://www.linkedin.com/in/ahmedkhaled40/)\n",
    "\n",
    "### Date Created: _04/09/2025_\n",
    "\n",
    "<center>~</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
